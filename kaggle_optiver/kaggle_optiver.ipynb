{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-18T21:57:53.266882Z",
     "iopub.status.busy": "2023-08-18T21:57:53.266515Z",
     "iopub.status.idle": "2023-08-18T21:57:53.350948Z",
     "shell.execute_reply": "2023-08-18T21:57:53.349490Z",
     "shell.execute_reply.started": "2023-08-18T21:57:53.266850Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cbt\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T22:38:26.851862Z",
     "iopub.status.busy": "2023-08-18T22:38:26.851477Z",
     "iopub.status.idle": "2023-08-18T22:38:35.853787Z",
     "shell.execute_reply": "2023-08-18T22:38:35.852860Z",
     "shell.execute_reply.started": "2023-08-18T22:38:26.851831Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features:\n",
    "\n",
    "## Volume and Duration\n",
    "1. Breadth (may not be relevant) - number of transactions in an interval\n",
    "2. VolumeAll: the total number of shares transacted in the interval\n",
    "3. VolumeAvg: the avg number of shares transacted in the interval\n",
    "4. VolumeMax: maximum num of shares transacted in one transaction in the interval.\n",
    "\n",
    "## Return and Imbalance:\n",
    "1. Lambda: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "The training data contain 481 days, covering the period of 3:50pm to 3:59pm at the Nasdaq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note Reference price is for all seconds but far price is only for seconds_in_bucket 300-540.\n",
    "In other words for 4:55-4:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifytrades import TradeClassification \n",
    "import datetime\n",
    "\n",
    "def lee_ready(data):\n",
    "\tdf = data.copy()\n",
    "\n",
    "\tdf[\"vol\"] = df.eval('bid_size + ask_size + matched_size + imbalance_size')\n",
    "\tdf.rename(columns={\"reference_price\" : \"price\"}, inplace=True)\n",
    "\n",
    "\t# seconds since midnight\n",
    "\tdf1 = df[[\"vol\", \"seconds_in_bucket\", \"price\", \"date_id\", \"stock_id\", \"ask_price\", \"bid_price\", \"ask_size\", \"bid_size\"]].copy()\n",
    "\n",
    "\tdf1['time'] = df1.index # + (16 * 3600) + (50 * 60)\n",
    "\n",
    "\task = df1[['ask_price', 'ask_size', 'time']].copy().rename(columns={\"ask_price\" : \"price\", \"ask_size\" : \"vol\"})\n",
    "\tbid = df1[['bid_price', 'bid_size', 'time']].copy().rename(columns={\"bid_price\" : \"price\", \"bid_size\" : \"vol\"})\n",
    "\n",
    "\ttc = TradeClassification(df1, Ask=ask, Bid=bid)\n",
    "\ttc.classify(method='lee_ready', freq=1, reduce_precision=False)\n",
    "\n",
    "\tdata = data.merge(tc.df_tr[[\"date_id\", \"stock_id\", \"seconds_in_bucket\", \"Initiator\", \"midpoint\"]], on=[\"date_id\", \"stock_id\", \"seconds_in_bucket\"], how=\"left\")\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that some stocks don't have an auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_data(df, training=False, full_data=False):\n",
    "\tdata = lee_ready(df)\n",
    "\t# data = df.set_index([\"stock_id\", \"date_id\", \"seconds_in_bucket\"])\n",
    "\n",
    "\tdata[\"imbalance_buy_sell\"] = data.imbalance_size * data.imbalance_buy_sell_flag\n",
    "\n",
    "\tparams = [\"imbalance_buy_sell\", \"reference_price\", \"matched_size\", \"wap_logreturns\", \"matched_ratio\"]\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = np.log(data.wap/data.wap.shift(1))\n",
    "\n",
    "\tdata[\"prev_wap\"] = data.groupby([\"date_id\", \"stock_id\"]).wap.shift(1)\n",
    "\n",
    "\tdata[\"PastReturn\"] = 1 - data.eval('wap /prev_wap')\n",
    "\n",
    "\tdata[\"matched_ratio\"] = data.imbalance_buy_sell_flag*data.imbalance_size/data.matched_size\n",
    "\n",
    "\n",
    "\tdata[\"imb_s1\"] = data.eval('(bid_size - ask_size)/(bid_size + ask_size)')\n",
    "\tdata[\"imb_s2\"] = data.eval('(imbalance_size - matched_size)/(matched_size + imbalance_size)')\n",
    "\n",
    "\tdata[\"VolumeAll\"] = data.eval('bid_size + ask_size + matched_size + imbalance_size') # explore\n",
    "\n",
    "\tdata[\"lambda\"] = data.eval('(bid_price - ask_price)/VolumeAll')\n",
    "\n",
    "\tdata[\"LobImbalance\"] = data.eval('(ask_size - bid_size)/VolumeAll')\n",
    "\tdata[\"TxnImbalance\"] = data.eval('VolumeAll*Initiator')\n",
    "\n",
    "\n",
    "\tif full_data == True:\n",
    "\t\treturn data\n",
    "\n",
    "\tdata = data.fillna(0)\n",
    "\tfeatures = [\"PastReturn\", \"lambda\", \"LobImbalance\", \"matched_ratio\", \"imb_s1\", \"imb_s2\", \"imbalance_buy_sell_flag\"]\n",
    "\tif training:\n",
    "\t\tX = data[features].to_numpy()\n",
    "\t\ty = data.target.to_numpy()\n",
    "\t\t# y = np.array(data.target).reshape(-1,1)\n",
    "\t\treturn X[np.isfinite(X).all(1)], y[np.isfinite(X).all(1)]\n",
    "\t\t# return X, y\n",
    "\n",
    "\tX = data[features].copy()\n",
    "\n",
    "\treturn X.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "We separate these 480 days into 5 pieces perform a 5-fold cross-validation on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ephraimsutherland/Documents/kaggle-optiver/kaggle_optiver/classifytrades.py:798: RuntimeWarning: invalid value encountered in cast\n",
      "  s = tick_rule(self.df_tr.price.values.astype(int), prices, index_p)\n",
      "/home/ephraimsutherland/Documents/kaggle-optiver/optiver_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "X, y = make_data(train, training=True)\n",
    "\n",
    "\n",
    "TUNING = False\n",
    "\n",
    "from tune import TuningSession\n",
    "\n",
    "if TUNING == True:\n",
    "    if getpass.getuser() == \"vinicius\":\n",
    "        hyperparam_dists_path = '/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/hyperparameters.yaml'\n",
    "    elif getpass.getuser() == \"ephraimsutherland\":\n",
    "        hyperparam_dists_path = '/home/ephraimsutherland/Documents/kaggle-optiver/kaggle_optiver/hyperparameters.yaml'\n",
    "\n",
    "    ts = TuningSession(hyperparam_dists_path=hyperparam_dists_path)\n",
    "    ts.run(data=X, labels=y)\n",
    "    ts.trials_dict['LGBMRegressor'].to_csv(\"lgbm_trials.csv\")\n",
    "    ts.trials_dict['RFRegressor'].to_csv(\"rf_trials.csv\")\n",
    "\n",
    "else:\n",
    "    trials_LGBM = pd.read_csv(\"lgbm_trials.csv\")\n",
    "    trials_RF = pd.read_csv(\"rf_trials.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_RF.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "trials_LGBM.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_trials=0.10\n",
    "best_trials_LGBM = trials_LGBM.sort_values('value')[:int(len(trials_LGBM)*percentage_of_trials)]\n",
    "best_trials_LGBM.drop(columns=[\"number\",\"value\",\"datetime_start\", \"datetime_complete\",\"duration\", \"state\"], inplace=True)\n",
    "# best_trials_LGBM.loc[:.best_trials_LGBM.columns.str.startswith('params_')]\n",
    "best_trials_LGBM = best_trials_LGBM.rename(columns=lambda x: re.sub('params_','',x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials_RF = trials_RF.sort_values('value')[:3]\n",
    "best_trials_RF.drop(columns=[\"number\",\"value\",\"datetime_start\", \"datetime_complete\",\"duration\", \"state\"], inplace=True)\n",
    "# best_trials_RF.loc[:.best_trials_RF.columns.str.startswith('params_')]\n",
    "best_trials_RF = best_trials_RF.rename(columns=lambda x: re.sub('params_','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials_LGBM.drop_duplicates(inplace=True)\n",
    "best_trials_RF.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(model, i, training=False):\n",
    "\tif training==True:\n",
    "\t\tmodel.fit(X,y)\n",
    "\t\tjoblib.dump(model, f'./models/model_{i}.model')\n",
    "\telse:\n",
    "\t\tmodel = joblib.load(f'./models/model_{i}.model')\n",
    "\treturn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM 0\n",
      "LGBM 1\n",
      "LGBM 2\n",
      "LGBM 3\n",
      "LGBM 4\n",
      "RF 0\n",
      "RF 1\n",
      "RF 2\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearRegression()\n",
    "\n",
    "model1.fit(X,y)\n",
    "model_list = []\n",
    "\n",
    "# model_list.append(model1)\n",
    "for i in range(len(best_trials_LGBM)):\n",
    "\tprint(\"LGBM\", i)\n",
    "\t\n",
    "\tvals = best_trials_LGBM.iloc[i]\n",
    "\tmodel = lgb.LGBMRegressor(objective='regression_l1', **vals)\n",
    "\tmodel_fit = models(model, \"LGBM\"+str(i), training=False)\n",
    "\tmodel_list.append(model_fit)\n",
    "\n",
    "\n",
    "for i in range(len(best_trials_RF)):\n",
    "\tprint(\"RF\", i)\n",
    "\t\n",
    "\tvals = best_trials_RF.iloc[i]\n",
    "\tmodel = RandomForestRegressor(**vals)\n",
    "\t# model = None\n",
    "\tmodel_fit = models(model, \"RF\"+str(i), training=False)\n",
    "\tmodel_list.append(model_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    X = make_data(test)\n",
    "    # sample_prediction['target'] = model.predict(X)\n",
    "    sample_prediction['target'] = np.mean([model.predict(X) for model in model_list], 0)\n",
    "    # sample_prediction['target'] = 0.5\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480_540_190,0.669063343502831\n",
      "480_540_191,-0.10323479642061406\n",
      "480_540_192,-0.4726706178442343\n",
      "480_540_193,-0.07967248250678398\n",
      "480_540_194,0.5186614778554246\n",
      "480_540_195,0.41593818706091495\n",
      "480_540_196,-0.3835122479397541\n",
      "480_540_197,0.9056433419265066\n",
      "480_540_198,0.5690122873193335\n",
      "480_540_199,-0.00045112135934086833\n"
     ]
    }
   ],
   "source": [
    "!tail submission.csv\n",
    "# sub = pd.read_csv(\"./example_test_files/sample_submission.csv\")\n",
    "sub = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "test = pd.read_csv(\"./example_test_files/test.csv\")\n",
    "\n",
    "revealed = pd.read_csv(\"./example_test_files/revealed_targets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub[sub.target != \"target\"]\n",
    "sub.target = sub.target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = train[[\"row_id\", \"target\"]].merge(sub, on=\"row_id\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.267661304787218"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.mean(np.abs(ans.target_x - ans.target_y))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Naive Estimate: 5.27941\n",
    "\n",
    "With bid-ask size imbalance: 5.279170945560908\n",
    "\n",
    "As above but adding imbalance-matched difference ratio: 5.278630645573058\n",
    "\n",
    "\n",
    "Same as above but using lgb: 5.278595988137708\n",
    "\n",
    "Now using LGBM and RF: 5.273744433871616\n",
    "\n",
    "Adding the LR initiator flag: 5.268223119261944\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver_env",
   "language": "python",
   "name": "optiver_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
