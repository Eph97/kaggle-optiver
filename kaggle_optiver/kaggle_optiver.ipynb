{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-18T21:57:53.266882Z",
     "iopub.status.busy": "2023-08-18T21:57:53.266515Z",
     "iopub.status.idle": "2023-08-18T21:57:53.350948Z",
     "shell.execute_reply": "2023-08-18T21:57:53.349490Z",
     "shell.execute_reply.started": "2023-08-18T21:57:53.266850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cbt\n",
    "import joblib\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T22:38:26.851862Z",
     "iopub.status.busy": "2023-08-18T22:38:26.851477Z",
     "iopub.status.idle": "2023-08-18T22:38:35.853787Z",
     "shell.execute_reply": "2023-08-18T22:38:35.852860Z",
     "shell.execute_reply.started": "2023-08-18T22:38:26.851831Z"
    }
   },
   "outputs": [],
   "source": [
    "# stock_prices = pd.read_csv(os.path.join(dirname, \"stock_prices.csv\"))\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features:\n",
    "\n",
    "## Volume and Duration\n",
    "1. Breadth (may not be relevant) - number of transactions in an interval\n",
    "2. VolumeAll: the total number of shares transacted in the interval\n",
    "3. VolumeAvg: the avg number of shares transacted in the interval\n",
    "4. VolumeMax: maximum num of shares transacted in one transaction in the interval.\n",
    "\n",
    "## Return and Imbalance:\n",
    "1. Lambda: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "The training data contain 481 days, covering the period of 3:50pm to 3:59pm at the Nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.date_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"matched_size\", \"imbalance_size\", \"imbalance_buy_sell_flag\"]]\n",
    "\n",
    "train[train.matched_size == 0]\n",
    "\n",
    "train[\"matched_ratio\"] = train.imbalance_buy_sell_flag*train.imbalance_size/train.matched_size\n",
    "train[\"test_ratio\"] = train.imbalance_buy_sell_flag*train.matched_size/train.imbalance_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420,\n",
       "       430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.loc[(train.stock_id == 0) & (train.date_id == 0) & (train.seconds_in_bucket == 0)]\n",
    "# train[[\"seconds_in_bucket\", \"wap\", \"stock_id\", \"date_id\", \"seconds_in_bucket\", \"matched_size\", \"imbalance_size\", \"imbalance_buy_sell_flag\", \"matched_ratio\"]]\n",
    "\n",
    "train[[\"seconds_in_bucket\", \"far_price\", \"stock_id\", \"date_id\"]].dropna().seconds_in_bucket.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note Reference price is for all seconds but far price is only for seconds_in_bucket 300-540.\n",
    "In other words for 4:55-4:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_id = train[train.matched_ratio.isna()].stock_id.unique()\n",
    "# train[train.stock_id.isin(stock_id)].seconds_in_bucket.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring features\n",
    "\n",
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that some stocks don't have an auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_data(df, training=False, full_data=False):\n",
    "\tdata = df.copy()\n",
    "\t# data = df.set_index([\"stock_id\", \"date_id\", \"seconds_in_bucket\"])\n",
    "\n",
    "\tdata[\"imbalance_buy_sell\"] = data.imbalance_size * data.imbalance_buy_sell_flag\n",
    "\n",
    "\tparams = [\"imbalance_buy_sell\", \"reference_price\", \"matched_size\", \"wap_logreturns\", \"matched_ratio\"]\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = np.log(data.wap/data.wap.shift(1))\n",
    "\n",
    "\tdata[\"prev_wap\"] = data.groupby([\"date_id\", \"stock_id\"]).wap.shift(1)\n",
    "\n",
    "\t# data[\"prev_wap\"] = data[\"prev_wap\"].fillna(0)\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = np.log(data.wap / data.prev_wap)\n",
    "\n",
    "\tdata[\"PastReturn\"] = 1 - data.eval('wap /prev_wap')\n",
    "\n",
    "\tdata[\"matched_ratio\"] = data.imbalance_buy_sell_flag*data.imbalance_size/data.matched_size\n",
    "\n",
    "\t# data[\"wap_man\"] = data.eval(\"(bid_price*ask_size + ask_price*bid_size)/(bid_size + ask_size)\")\n",
    "\n",
    "\tdata[\"imb_s1\"] = data.eval('(bid_size - ask_size)/(bid_size + ask_size)')\n",
    "\tdata[\"imb_s2\"] = data.eval('(imbalance_size - matched_size)/(matched_size + imbalance_size)')\n",
    "\n",
    "\tdata[\"VolumeAll\"] = data.eval('bid_size + ask_size') # explore\n",
    "\n",
    "\tdata[\"lambda\"] = data.eval('(bid_price - ask_price)/VolumeAll')\n",
    "\n",
    "\tdata[\"LobImbalance\"] = data.eval('(ask_size - bid_size)/VolumeAll')\n",
    "\tdata[\"TxnImbalance\"] = data.eval('(imbalance_size - matched_size)/VolumeAll')\n",
    "\n",
    "\n",
    "\n",
    "\t# data[\"matched_ratio\"] = data[\"matched_ratio\"].fillna(0)\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = data[\"wap_logreturns\"].fillna(0)\n",
    "\n",
    "\t# data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\t# data['ewa6'] = data.groupby([\"stock_id\",\"date_id\"]).wap.transform(lambda x : x.ewm(span=6, adjust=False).mean()).values\n",
    "\t# data['ewa12'] = data.groupby([\"stock_id\",\"date_id\"]).wap.transform(lambda x : x.ewm(span=12, adjust=False).mean()).values\n",
    "\n",
    "\tif full_data == True:\n",
    "\t\treturn data\n",
    "\n",
    "\tdata = data.fillna(0)\n",
    "\tfeatures = [\"PastReturn\", \"lambda\", \"LobImbalance\", \"matched_ratio\", \"imb_s1\", \"imb_s2\", \"imbalance_buy_sell_flag\"]\n",
    "\tif training:\n",
    "\t\tX = data[features].to_numpy()\n",
    "\t\ty = data.target.to_numpy()\n",
    "\t\t# y = np.array(data.target).reshape(-1,1)\n",
    "\t\treturn X[np.isfinite(X).all(1)], y[np.isfinite(X).all(1)]\n",
    "\t\t# return X, y\n",
    "\n",
    "\tX = data[features].copy()\n",
    "\n",
    "\t# X.wap_logreturns = X.wap_logreturns.fillna(0)\n",
    "\t# X.matched_ratio = X.matched_ratio.fillna(0)\n",
    "\t# X.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\treturn X.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          10199673.95\n",
       "1           1475610.34\n",
       "2           1516488.16\n",
       "3           6472063.35\n",
       "4          17413064.99\n",
       "              ...     \n",
       "5237975    25839638.85\n",
       "5237976     8838188.64\n",
       "5237977    12725436.10\n",
       "5237978    93772372.21\n",
       "5237979    22189391.61\n",
       "Length: 5237980, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_data(train, full_data=True)\n",
    "\n",
    "df[(df.matched_size - df.imbalance_size < 0)]\n",
    "\n",
    "df.eval(\"(matched_size - imbalance_size)\").abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "We separate these 480 days into 5 pieces perform a 5-fold cross-validation on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "X, y = make_data(train, training=True)\n",
    "\n",
    "from tune import TuningSession\n",
    "\n",
    "if getpass.getuser() == \"vinicius\":\n",
    "    hyperparam_dists_path = '/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/hyperparameters.yaml'\n",
    "elif getpass.getuser == \"ephraimsutherland\":\n",
    "    hyperparam_dists_path = '/Users/ephraimsutherland/Documents/kaggle-optiver/kaggle_optiver/hyperparameters.yaml'\n",
    "\n",
    "ts = TuningSession(hyperparam_dists_path=hyperparam_dists_path)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "#                                    random_state=104,\n",
    "#                                    test_size=0.25,\n",
    "#                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:59:11] Preparing and Transforming data\n",
      "[17:59:11] Starting LGBMRegressor's study\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:11,794] A new study created in memory with name: no-name-82dd456a-26c3-40c9-b92f-f4cea5b824a4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:17,025] Trial 0 finished with value: 6.333961677505403 and parameters: {'n_estimators': 8, 'max_depth': 10, 'num_leaves': 128, 'learning_rate': 0.6000000000000001, 'reg_lambda': 0.15000000000000002, 'boosting_type': 'gbdt', 'subsample': 0.9000000000000001, 'colsample_bytree': 0.8, 'reg_alpha': 0.7000000000000001, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 0 with value: 6.333961677505403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:21,288] Trial 1 finished with value: 6.337748455243783 and parameters: {'n_estimators': 4, 'max_depth': 10, 'num_leaves': 144, 'learning_rate': 0.25, 'reg_lambda': 0.15000000000000002, 'boosting_type': 'dart', 'subsample': 0.7, 'colsample_bytree': 0.7000000000000001, 'reg_alpha': 0.30000000000000004, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 0 with value: 6.333961677505403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:26,157] Trial 2 finished with value: 6.330827071300677 and parameters: {'n_estimators': 16, 'max_depth': 4, 'num_leaves': 48, 'learning_rate': 0.4, 'reg_lambda': 0.45, 'boosting_type': 'gbdt', 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 2 with value: 6.330827071300677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:30,789] Trial 3 finished with value: 6.333325615995297 and parameters: {'n_estimators': 16, 'max_depth': 5, 'num_leaves': 16, 'learning_rate': 0.9500000000000001, 'reg_lambda': 1.0, 'boosting_type': 'gbdt', 'subsample': 0.3, 'colsample_bytree': 0.8, 'reg_alpha': 0.45, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 2 with value: 6.330827071300677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:33,804] Trial 4 finished with value: 6.336345845042745 and parameters: {'n_estimators': 4, 'max_depth': 7, 'num_leaves': 16, 'learning_rate': 0.9500000000000001, 'reg_lambda': 0.25, 'boosting_type': 'gbdt', 'subsample': 0.7, 'colsample_bytree': 0.7000000000000001, 'reg_alpha': 0.15000000000000002, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 2 with value: 6.330827071300677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:43,860] Trial 5 finished with value: 6.34539091748325 and parameters: {'n_estimators': 20, 'max_depth': 9, 'num_leaves': 160, 'learning_rate': 0.9000000000000001, 'reg_lambda': 0.6000000000000001, 'boosting_type': 'gbdt', 'subsample': 0.4, 'colsample_bytree': 0.4, 'reg_alpha': 0.30000000000000004, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 2 with value: 6.330827071300677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:47,771] Trial 6 finished with value: 6.346098776712773 and parameters: {'n_estimators': 8, 'max_depth': 5, 'num_leaves': 144, 'learning_rate': 0.4, 'reg_lambda': 0.25, 'boosting_type': 'gbdt', 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_alpha': 1.0, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 2 with value: 6.330827071300677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 17:59:54,079] Trial 7 finished with value: 6.333121467555759 and parameters: {'n_estimators': 16, 'max_depth': 5, 'num_leaves': 16, 'learning_rate': 0.8500000000000001, 'reg_lambda': 0.7000000000000001, 'boosting_type': 'dart', 'subsample': 0.3, 'colsample_bytree': 0.6000000000000001, 'reg_alpha': 0.1, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 2 with value: 6.330827071300677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 18:00:10,064] Trial 8 finished with value: 6.334074996528038 and parameters: {'n_estimators': 20, 'max_depth': 8, 'num_leaves': 64, 'learning_rate': 0.1, 'reg_lambda': 0.30000000000000004, 'boosting_type': 'dart', 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.45, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 2 with value: 6.330827071300677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-19 18:00:14,076] Trial 9 finished with value: 6.346415558779484 and parameters: {'n_estimators': 4, 'max_depth': 8, 'num_leaves': 128, 'learning_rate': 0.6000000000000001, 'reg_lambda': 0.8, 'boosting_type': 'dart', 'subsample': 0.6000000000000001, 'colsample_bytree': 0.4, 'reg_alpha': 0.1, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 2 with value: 6.330827071300677.\n",
      "[18:00:14] Finished LGBMRegressor's study\n",
      "[18:00:14] Finished\n"
     ]
    }
   ],
   "source": [
    "ts.run(data=X, labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_boosting_type</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_force_row_wise</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_n_jobs</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>params_random_state</th>\n",
       "      <th>params_reg_alpha</th>\n",
       "      <th>params_reg_lambda</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.330827</td>\n",
       "      <td>2023-12-19 17:59:21.289331</td>\n",
       "      <td>2023-12-19 17:59:26.157406</td>\n",
       "      <td>0 days 00:00:04.868075</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     value             datetime_start          datetime_complete  \\\n",
       "2       2  6.330827 2023-12-19 17:59:21.289331 2023-12-19 17:59:26.157406   \n",
       "\n",
       "                duration params_boosting_type  params_colsample_bytree  \\\n",
       "2 0 days 00:00:04.868075                 gbdt                      0.8   \n",
       "\n",
       "   params_force_row_wise  params_learning_rate  params_max_depth  \\\n",
       "2                   True                   0.4                 4   \n",
       "\n",
       "   params_n_estimators  params_n_jobs  params_num_leaves  params_random_state  \\\n",
       "2                   16             -1                 48                   42   \n",
       "\n",
       "   params_reg_alpha  params_reg_lambda  params_subsample     state  \n",
       "2               0.0               0.45               0.7  COMPLETE  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_LGBM = ts.trials_dict['LGBMRegressor']\n",
    "trials_LGBM.sort_values('value')[:len(trials_LGBM)//10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(model, i, training=False):\n",
    "\tif training==True:\n",
    "\t\tmodel.fit(X,y)\n",
    "\t\tjoblib.dump(model, './models/model_{i}.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model2 = lgb.LGBMRegressor(objective='regression_l1', n_estimators=500)\n",
    "\n",
    "# models(model1)\n",
    "\n",
    "for i,model in enumerate([model1]):\n",
    "\t# print(i)\n",
    "\tmodels(model, i, training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,\n",
       "       260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380,\n",
       "       390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510,\n",
       "       520, 530, 540])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[train.seconds_in_bucket > 10].head()\n",
    "# train.loc[train.stock_id==1,['target', 'time_id', 'stock_id', 'seconds_in_bucket']]\n",
    "train[train.stock_id==1]['seconds_in_bucket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    X = make_data(test)\n",
    "    # sample_prediction['target'] = model.predict(X)\n",
    "    sample_prediction['target'] = model1.predict(X)\n",
    "    # sample_prediction['target'] = 0.5\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: submission.csv: No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mtail submission.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# sub = pd.read_csv(\"./example_test_files/sample_submission.csv\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sub \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39msubmission.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./example_test_files/test.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m revealed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./example_test_files/revealed_targets.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'submission.csv'"
     ]
    }
   ],
   "source": [
    "!tail submission.csv\n",
    "# sub = pd.read_csv(\"./example_test_files/sample_submission.csv\")\n",
    "sub = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "test = pd.read_csv(\"./example_test_files/test.csv\")\n",
    "\n",
    "revealed = pd.read_csv(\"./example_test_files/revealed_targets.csv\")\n",
    "\n",
    "\n",
    "# test.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sub \u001b[39m=\u001b[39m sub[sub\u001b[39m.\u001b[39mtarget \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sub\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m sub\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "sub = sub[sub.target != \"target\"]\n",
    "sub.target = sub.target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ans \u001b[39m=\u001b[39m train[[\u001b[39m\"\u001b[39m\u001b[39mrow_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mmerge(sub, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrow_id\u001b[39m\u001b[39m\"\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "ans = train[[\"row_id\", \"target\"]].merge(sub, on=\"row_id\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2774822936432155"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.mean(np.abs(ans.target_x - ans.target_y))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Naive Estimate: 5.27941\n",
    "\n",
    "With bid-ask size imbalance: 5.279170945560908\n",
    "\n",
    "As above but adding imbalance-matched difference ratio: 5.278630645573058\n",
    "\n",
    "\n",
    "Same as above but using lgb: 5.278595988137708"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
