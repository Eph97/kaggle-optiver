{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-18T21:57:53.266882Z",
     "iopub.status.busy": "2023-08-18T21:57:53.266515Z",
     "iopub.status.idle": "2023-08-18T21:57:53.350948Z",
     "shell.execute_reply": "2023-08-18T21:57:53.349490Z",
     "shell.execute_reply.started": "2023-08-18T21:57:53.266850Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cbt\n",
    "import joblib\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T22:38:26.851862Z",
     "iopub.status.busy": "2023-08-18T22:38:26.851477Z",
     "iopub.status.idle": "2023-08-18T22:38:35.853787Z",
     "shell.execute_reply": "2023-08-18T22:38:35.852860Z",
     "shell.execute_reply.started": "2023-08-18T22:38:26.851831Z"
    }
   },
   "outputs": [],
   "source": [
    "# stock_prices = pd.read_csv(os.path.join(dirname, \"stock_prices.csv\"))\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features:\n",
    "\n",
    "## Volume and Duration\n",
    "1. Breadth (may not be relevant) - number of transactions in an interval\n",
    "2. VolumeAll: the total number of shares transacted in the interval\n",
    "3. VolumeAvg: the avg number of shares transacted in the interval\n",
    "4. VolumeMax: maximum num of shares transacted in one transaction in the interval.\n",
    "\n",
    "## Return and Imbalance:\n",
    "1. Lambda: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "The training data contain 481 days, covering the period of 3:50pm to 3:59pm at the Nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.date_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "We separate these 480 days into 5 pieces perform a 5-fold cross-validation on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"matched_size\", \"imbalance_size\", \"imbalance_buy_sell_flag\"]]\n",
    "\n",
    "train[train.matched_size == 0]\n",
    "\n",
    "train[\"matched_ratio\"] = train.imbalance_buy_sell_flag*train.imbalance_size/train.matched_size\n",
    "train[\"test_ratio\"] = train.imbalance_buy_sell_flag*train.matched_size/train.imbalance_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[(train.stock_id == 0) & (train.date_id == 0) & (train.seconds_in_bucket == 0)]\n",
    "# train[[\"seconds_in_bucket\", \"wap\", \"stock_id\", \"date_id\", \"seconds_in_bucket\", \"matched_size\", \"imbalance_size\", \"imbalance_buy_sell_flag\", \"matched_ratio\"]]\n",
    "\n",
    "# train[[\"seconds_in_bucket\", \"far_price\", \"stock_id\", \"date_id\"]].dropna().seconds_in_bucket.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note Reference price is for all seconds but far price is only for seconds_in_bucket 300-540.\n",
    "In other words for 4:55-4:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_id = train[train.matched_ratio.isna()].stock_id.unique()\n",
    "# train[train.stock_id.isin(stock_id)].seconds_in_bucket.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring features\n",
    "\n",
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that some stocks don't have an auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_data(df, training=False, full_data=False):\n",
    "\tdata = df.copy()\n",
    "\t# data = df.set_index([\"stock_id\", \"date_id\", \"seconds_in_bucket\"])\n",
    "\n",
    "\tdata[\"imbalance_buy_sell\"] = data.imbalance_size * data.imbalance_buy_sell_flag\n",
    "\n",
    "\tparams = [\"imbalance_buy_sell\", \"reference_price\", \"matched_size\", \"wap_logreturns\", \"matched_ratio\"]\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = np.log(data.wap/data.wap.shift(1))\n",
    "\n",
    "\tdata[\"prev_wap\"] = data.groupby([\"date_id\", \"stock_id\"]).wap.shift(1)\n",
    "\n",
    "\t# data[\"prev_wap\"] = data[\"prev_wap\"].fillna(0)\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = np.log(data.wap / data.prev_wap)\n",
    "\n",
    "\tdata[\"PastReturn\"] = 1 - data.eval('wap /prev_wap')\n",
    "\n",
    "\tdata[\"matched_ratio\"] = data.imbalance_buy_sell_flag*data.imbalance_size/data.matched_size\n",
    "\n",
    "\t# data[\"wap_man\"] = data.eval(\"(bid_price*ask_size + ask_price*bid_size)/(bid_size + ask_size)\")\n",
    "\n",
    "\tdata[\"imb_s1\"] = data.eval('(bid_size - ask_size)/(bid_size + ask_size)')\n",
    "\tdata[\"imb_s2\"] = data.eval('(imbalance_size - matched_size)/(matched_size + imbalance_size)')\n",
    "\n",
    "\tdata[\"VolumeAll\"] = data.eval('bid_size + ask_size') # explore\n",
    "\n",
    "\tdata[\"lambda\"] = data.eval('(bid_price - ask_price)/VolumeAll')\n",
    "\n",
    "\tdata[\"LobImbalance\"] = data.eval('(ask_size - bid_size)/VolumeAll')\n",
    "\tdata[\"TxnImbalance\"] = data.eval('(imbalance_size - matched_size)/VolumeAll')\n",
    "\n",
    "\n",
    "\n",
    "\t# data[\"matched_ratio\"] = data[\"matched_ratio\"].fillna(0)\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = data[\"wap_logreturns\"].fillna(0)\n",
    "\n",
    "\t# data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\t# data['ewa6'] = data.groupby([\"stock_id\",\"date_id\"]).wap.transform(lambda x : x.ewm(span=6, adjust=False).mean()).values\n",
    "\t# data['ewa12'] = data.groupby([\"stock_id\",\"date_id\"]).wap.transform(lambda x : x.ewm(span=12, adjust=False).mean()).values\n",
    "\n",
    "\tif full_data == True:\n",
    "\t\treturn data\n",
    "\n",
    "\tdata = data.fillna(0)\n",
    "\tfeatures = [\"PastReturn\", \"lambda\", \"LobImbalance\", \"matched_ratio\", \"imb_s1\", \"imb_s2\", \"imbalance_buy_sell_flag\"]\n",
    "\tif training:\n",
    "\t\tX = data[features].to_numpy()\n",
    "\t\ty = data.target.to_numpy()\n",
    "\t\t# y = np.array(data.target).reshape(-1,1)\n",
    "\t\treturn X[np.isfinite(X).all(1)], y[np.isfinite(X).all(1)]\n",
    "\t\t# return X, y\n",
    "\n",
    "\tX = data[features].copy()\n",
    "\n",
    "\t# X.wap_logreturns = X.wap_logreturns.fillna(0)\n",
    "\t# X.matched_ratio = X.matched_ratio.fillna(0)\n",
    "\t# X.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\treturn X.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          10199673.95\n",
       "1           1475610.34\n",
       "2           1516488.16\n",
       "3           6472063.35\n",
       "4          17413064.99\n",
       "              ...     \n",
       "5237975    25839638.85\n",
       "5237976     8838188.64\n",
       "5237977    12725436.10\n",
       "5237978    93772372.21\n",
       "5237979    22189391.61\n",
       "Length: 5237980, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_data(train, full_data=True)\n",
    "\n",
    "df[(df.matched_size - df.imbalance_size < 0)]\n",
    "\n",
    "df.eval(\"(matched_size - imbalance_size)\").abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinicius/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "X, y = make_data(train, training=True)\n",
    "\n",
    "from tune import TuningSession\n",
    "hyperparam_dists_path = '/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/hyperparameters.yaml'\n",
    "\n",
    "ts = TuningSession(hyperparam_dists_path=hyperparam_dists_path)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "#                                    random_state=104,\n",
    "#                                    test_size=0.25,\n",
    "#                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:18:02] Preparing and Transforming data\n",
      "[19:18:02] Starting LGBMRegressor's study\n",
      "[I 2023-12-15 19:18:02,405] A new study created in memory with name: no-name-b96a50a4-b123-4831-a595-c38c6c969f50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-15 19:18:07,111] Trial 0 finished with value: 6.333961677505403 and parameters: {'n_estimators': 8, 'max_depth': 10, 'num_leaves': 128, 'learning_rate': 0.6000000000000001, 'reg_lambda': 0.15000000000000002, 'boosting_type': 'gbdt', 'subsample': 0.9000000000000001, 'colsample_bytree': 0.8, 'reg_alpha': 0.7000000000000001, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 0 with value: 6.333961677505403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.039076\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.046583\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.054309\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.049900\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -0.047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-15 19:18:11,051] Trial 1 finished with value: 6.337748455243783 and parameters: {'n_estimators': 4, 'max_depth': 10, 'num_leaves': 144, 'learning_rate': 0.25, 'reg_lambda': 0.15000000000000002, 'boosting_type': 'dart', 'subsample': 0.7, 'colsample_bytree': 0.7000000000000001, 'reg_alpha': 0.30000000000000004, 'force_row_wise': True, 'n_jobs': -1, 'random_state': 42}. Best is trial 0 with value: 6.333961677505403.\n",
      "[19:18:11] Finished LGBMRegressor's study\n",
      "[19:18:11] Finished\n"
     ]
    }
   ],
   "source": [
    "ts.run(data=X, labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(model, i, training=False):\n",
    "\tif training==True:\n",
    "\t\tmodel.fit(X,y)\n",
    "\t\tjoblib.dump(model, './models/model_{i}.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model2 = lgb.LGBMRegressor(objective='regression_l1', n_estimators=500)\n",
    "\n",
    "# models(model1)\n",
    "\n",
    "for i,model in enumerate([model1]):\n",
    "\t# print(i)\n",
    "\tmodels(model, i, training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,\n",
       "       260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380,\n",
       "       390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510,\n",
       "       520, 530, 540])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[train.seconds_in_bucket > 10].head()\n",
    "# train.loc[train.stock_id==1,['target', 'time_id', 'stock_id', 'seconds_in_bucket']]\n",
    "train[train.stock_id==1]['seconds_in_bucket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    X = make_data(test)\n",
    "    # sample_prediction['target'] = model.predict(X)\n",
    "    sample_prediction['target'] = model1.predict(X)\n",
    "    # sample_prediction['target'] = 0.5\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: submission.csv: No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mtail submission.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# sub = pd.read_csv(\"./example_test_files/sample_submission.csv\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sub \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39msubmission.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./example_test_files/test.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m revealed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./example_test_files/revealed_targets.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Projects/kaggle/kaggle-optiver/optiver_env/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'submission.csv'"
     ]
    }
   ],
   "source": [
    "!tail submission.csv\n",
    "# sub = pd.read_csv(\"./example_test_files/sample_submission.csv\")\n",
    "sub = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "test = pd.read_csv(\"./example_test_files/test.csv\")\n",
    "\n",
    "revealed = pd.read_csv(\"./example_test_files/revealed_targets.csv\")\n",
    "\n",
    "\n",
    "# test.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sub \u001b[39m=\u001b[39m sub[sub\u001b[39m.\u001b[39mtarget \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sub\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m sub\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "sub = sub[sub.target != \"target\"]\n",
    "sub.target = sub.target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vinicius/Projects/kaggle/kaggle-optiver/kaggle_optiver/kaggle_optiver.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ans \u001b[39m=\u001b[39m train[[\u001b[39m\"\u001b[39m\u001b[39mrow_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mmerge(sub, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrow_id\u001b[39m\u001b[39m\"\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "ans = train[[\"row_id\", \"target\"]].merge(sub, on=\"row_id\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2774822936432155"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.mean(np.abs(ans.target_x - ans.target_y))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Naive Estimate: 5.27941\n",
    "\n",
    "With bid-ask size imbalance: 5.279170945560908\n",
    "\n",
    "As above but adding imbalance-matched difference ratio: 5.278630645573058\n",
    "\n",
    "\n",
    "Same as above but using lgb: 5.278595988137708"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
