{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-18T21:57:53.266882Z",
     "iopub.status.busy": "2023-08-18T21:57:53.266515Z",
     "iopub.status.idle": "2023-08-18T21:57:53.350948Z",
     "shell.execute_reply": "2023-08-18T21:57:53.349490Z",
     "shell.execute_reply.started": "2023-08-18T21:57:53.266850Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb \n",
    "import catboost as cbt \n",
    "import joblib\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T22:38:26.851862Z",
     "iopub.status.busy": "2023-08-18T22:38:26.851477Z",
     "iopub.status.idle": "2023-08-18T22:38:35.853787Z",
     "shell.execute_reply": "2023-08-18T22:38:35.852860Z",
     "shell.execute_reply.started": "2023-08-18T22:38:26.851831Z"
    }
   },
   "outputs": [],
   "source": [
    "# stock_prices = pd.read_csv(os.path.join(dirname, \"stock_prices.csv\"))\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features:\n",
    "\n",
    "## Volume and Duration\n",
    "1. Breadth (may not be relevant) - number of transactions in an interval\n",
    "2. VolumeAll: the total number of shares transacted in the interval\n",
    "3. VolumeAvg: the avg number of shares transacted in the interval\n",
    "4. VolumeMax: maximum num of shares transacted in one transaction in the interval.\n",
    "\n",
    "## Return and Imbalance:\n",
    "1. Lambda: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[[\"matched_size\", \"imbalance_size\", \"imbalance_buy_sell_flag\"]]\n",
    "\n",
    "# train[train.matched_size == 0]\n",
    "\n",
    "# train[\"matched_ratio\"] = train.imbalance_buy_sell_flag*train.imbalance_size/train.matched_size\n",
    "# train[\"test_ratio\"] = train.imbalance_buy_sell_flag*train.matched_size/train.imbalance_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[(train.stock_id == 0) & (train.date_id == 0) & (train.seconds_in_bucket == 0)]\n",
    "# train[[\"seconds_in_bucket\", \"wap\", \"stock_id\", \"date_id\", \"seconds_in_bucket\", \"matched_size\", \"imbalance_size\", \"imbalance_buy_sell_flag\", \"matched_ratio\"]]\n",
    "\n",
    "# train[[\"seconds_in_bucket\", \"far_price\", \"stock_id\", \"date_id\"]].dropna().seconds_in_bucket.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note Reference price is for all seconds but far price is only for seconds_in_bucket 300-540.\n",
    "In other words for 4:55-4:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_id = train[train.matched_ratio.isna()].stock_id.unique()\n",
    "# train[train.stock_id.isin(stock_id)].seconds_in_bucket.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring features\n",
    "\n",
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that some stocks don't have an auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_data(df, training=False, full_data=False):\n",
    "\tdata = df.copy()\n",
    "\t# data = df.set_index([\"stock_id\", \"date_id\", \"seconds_in_bucket\"])\n",
    "\n",
    "\tdata[\"imbalance_buy_sell\"] = data.imbalance_size * data.imbalance_buy_sell_flag\n",
    "\n",
    "\tparams = [\"imbalance_buy_sell\", \"reference_price\", \"matched_size\", \"wap_logreturns\", \"matched_ratio\"]\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = np.log(data.wap/data.wap.shift(1))\n",
    "\n",
    "\tdata[\"prev_wap\"] = data.groupby([\"date_id\", \"stock_id\"]).wap.shift(1)\n",
    "\n",
    "\t# data[\"prev_wap\"] = data[\"prev_wap\"].fillna(0)\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = np.log(data.wap / data.prev_wap)\n",
    "\n",
    "\tdata[\"PastReturn\"] = 1 - data.eval('wap /prev_wap')\n",
    "\n",
    "\tdata[\"matched_ratio\"] = data.imbalance_buy_sell_flag*data.imbalance_size/data.matched_size\n",
    "\n",
    "\t# data[\"wap_man\"] = data.eval(\"(bid_price*ask_size + ask_price*bid_size)/(bid_size + ask_size)\")\n",
    "\n",
    "\tdata[\"imb_s1\"] = data.eval('(bid_size - ask_size)/(bid_size + ask_size)')\n",
    "\tdata[\"imb_s2\"] = data.eval('(imbalance_size - matched_size)/(matched_size + imbalance_size)')\n",
    "\n",
    "\tdata[\"VolumeAll\"] = data.eval('bid_size + ask_size') # explore\n",
    "\n",
    "\tdata[\"lambda\"] = data.eval('(bid_price - ask_price)/VolumeAll')\n",
    "\n",
    "\tdata[\"LobImbalance\"] = data.eval('(ask_size - bid_size)/VolumeAll')\n",
    "\tdata[\"TxnImbalance\"] = data.eval('(imbalance_size - matched_size)/VolumeAll')\n",
    "\n",
    "\t\n",
    "\n",
    "\t# data[\"matched_ratio\"] = data[\"matched_ratio\"].fillna(0)\n",
    "\n",
    "\t# data[\"wap_logreturns\"] = data[\"wap_logreturns\"].fillna(0)\n",
    "\n",
    "\t# data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\t# data['ewa6'] = data.groupby([\"stock_id\",\"date_id\"]).wap.transform(lambda x : x.ewm(span=6, adjust=False).mean()).values\n",
    "\t# data['ewa12'] = data.groupby([\"stock_id\",\"date_id\"]).wap.transform(lambda x : x.ewm(span=12, adjust=False).mean()).values\n",
    "\n",
    "\tif full_data == True:\n",
    "\t\treturn data\n",
    "\n",
    "\tdata = data.fillna(0)\n",
    "\tfeatures = [\"PastReturn\", \"lambda\", \"LobImbalance\", \"matched_ratio\", \"imb_s1\", \"imb_s2\", \"imbalance_buy_sell_flag\"]\n",
    "\tif training:\n",
    "\t\tX = data[features].to_numpy()\n",
    "\t\ty = data.target.to_numpy()\n",
    "\t\t# y = np.array(data.target).reshape(-1,1)\n",
    "\t\treturn X[np.isfinite(X).all(1)], y[np.isfinite(X).all(1)]\n",
    "\t\t# return X, y\n",
    "\n",
    "\tX = data[features].copy()\n",
    "\n",
    "\t# X.wap_logreturns = X.wap_logreturns.fillna(0)\n",
    "\t# X.matched_ratio = X.matched_ratio.fillna(0)\n",
    "\t# X.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\treturn X.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          10199673.95\n",
       "1           1475610.34\n",
       "2           1516488.16\n",
       "3           6472063.35\n",
       "4          17413064.99\n",
       "              ...     \n",
       "5237975    25839638.85\n",
       "5237976     8838188.64\n",
       "5237977    12725436.10\n",
       "5237978    93772372.21\n",
       "5237979    22189391.61\n",
       "Length: 5237980, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_data(train, full_data=True)\n",
    "\n",
    "df[(df.matched_size - df.imbalance_size < 0)]\n",
    "\n",
    "df.eval(\"(matched_size - imbalance_size)\").abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_data(train, training=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "                                   random_state=104,\n",
    "                                   test_size=0.25,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(model, i, training=False):\n",
    "\tif training==True:\n",
    "\t\tmodel.fit(X,y)\n",
    "\t\tjoblib.dump(model, './models/model_{i}.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model2 = lgb.LGBMRegressor(objective='regression_l1', n_estimators=500)\n",
    "\n",
    "# models(model1)\n",
    "\n",
    "for i,model in enumerate([model1]):\n",
    "\t# print(i)\n",
    "\tmodels(model, i, training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,\n",
       "       260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380,\n",
       "       390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510,\n",
       "       520, 530, 540])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[train.seconds_in_bucket > 10].head()\n",
    "# train.loc[train.stock_id==1,['target', 'time_id', 'stock_id', 'seconds_in_bucket']]\n",
    "train[train.stock_id==1]['seconds_in_bucket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    X = make_data(test)\n",
    "    # sample_prediction['target'] = model.predict(X)\n",
    "    sample_prediction['target'] = model1.predict(X)\n",
    "    # sample_prediction['target'] = 0.5\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480_540_190,1.0563787974342373\n",
      "480_540_191,-0.3573274049049089\n",
      "480_540_192,-0.6177932619790639\n",
      "480_540_193,0.005825103867730691\n",
      "480_540_194,0.9774944035979164\n",
      "480_540_195,1.1090903205606093\n",
      "480_540_196,-0.9736313810959997\n",
      "480_540_197,1.3347555625279806\n",
      "480_540_198,1.2858672794543997\n",
      "480_540_199,-0.16189260933999208\n"
     ]
    }
   ],
   "source": [
    "!tail submission.csv\n",
    "# sub = pd.read_csv(\"./example_test_files/sample_submission.csv\")\n",
    "sub = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "test = pd.read_csv(\"./example_test_files/test.csv\")\n",
    "\n",
    "revealed = pd.read_csv(\"./example_test_files/revealed_targets.csv\")\n",
    "\n",
    "\n",
    "# test.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub[sub.target != \"target\"]\n",
    "sub.target = sub.target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = train[[\"row_id\", \"target\"]].merge(sub, on=\"row_id\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2774822936432155"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.mean(np.abs(ans.target_x - ans.target_y))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Naive Estimate: 5.27941\n",
    "\n",
    "With bid-ask size imbalance: 5.279170945560908\n",
    "\n",
    "As above but adding imbalance-matched difference ratio: 5.278630645573058\n",
    "\n",
    "\n",
    "Same as above but using lgb: 5.278595988137708"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver_env",
   "language": "python",
   "name": "optiver_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
